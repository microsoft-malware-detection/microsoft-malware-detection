# Final Project

# Project Rubric
https://bbhosted.cuny.edu/bbcswebdav/pid-66303863-dt-content-rid-512581371_1/courses/CTY01_DSE_I2100_41582_1222_1/project_rubric21.html




# Abstract - Satesh

# Introduction - Satesh
- State your data and research question(s). Indicate why it is important.

- Describe your research plan so that readers can easily follow your thought process and the flow of the report. 
- Please also include key results at the beginning so that readers know to look for. 
- Here you can very briefly mention any important data cleaning or preparation. Do not talk about virtual results i.e. things you tried or wanted to do but didn’t do. Virtual results are worse than worthless. They highlight failure. 



Given metrics and telemetry data from Windows Defender, the goal of this project is to provide an estimation for how likely a Microsoft computer is to be infected by malware. The significance of this project is to utilize Machine Learning as a tool to explore potential underlying relationships through data Windows Defender collects. In practice this would be a useful tool to enable Microsoft computer owners to understand how likely it is that their computer is at risk for a malware attack.

Mobile devices are subject to 7000+ malware attacks every hour. [1] Additionally, AV-Test (an independent research institute for IT Security from Germany) registers approximately 400,000 new malware per day [2]
Malware authors may dynamically generates malware using obfuscation and replication techniques [3, 4]. Through discovering these facts utilizing machine learning to figure out if a machine is subject to malware would save Windows users from the malware threats that exist. Transparency about security vulnerabilities is one of the problems that companies in the 21st century struggle with, tackling this project will help provide the transparency that is missing. 



# Background - Paul

# Data - Satesh
## Microsoft Malware Prediction Kaggle Competition
The original dataset can be observed from the following [Kaggle Competition](https://www.kaggle.com/competitions/microsoft-malware-prediction/data?select=train.csv). 

Since the problem was taken from a Kaggle competition one caveat worth mentioning is there is a train.csv and test.csv. In Kaggle competitions, users only recieve the ground truth to the test.csv results when submitting results to the competition. Since the training data alone had approximately 8 million data points, this project used 33% of train.csv as a holdout set and the rest of the data for training. 

## Data Exploration 
Given the nature of the problem being classification, one of the first things to observe is if the data has balanced or imbalanced classes. From the image below we've identified the probelm is balanced. 

![](https://i.imgur.com/Zo0Sz1h.png)


The data is compromised of approximately 8 million rows and 82 columns. Each row uniquely identifies an individual Windows device, 82 columns represent several features and one column indicates whether the Machine has malware. 

![](https://i.imgur.com/teIzsKv.png)

Above is a distribution of the data-types of each feature;where there is an even balance of numeric-types, categoricals and booleans. 


Examples of numerical features include:
- Total RAM
- Display size 
- CUP core counts 

Examples of boolean features incldue:
- If antivirus is enabled
- If Firewall is enabled
- If the device is a Virtual Machine
- If a machine is gaming based on hardware

Examples of categorical features include:
- Windows Product Type (Windows 7,10 ,etc)
- Engine/OS/Software versions 
- Processor Type

## Data Cleaning

The first step in data cleaning consisted of handling null cases in the dataset. The figure below shows a distribution of the 44 features that contained null values. From a first glance two extremes are quite clear in the Null cases. First, there are 7 features where the total amount of nulls is more than half the entire dataset. Second, there are a lot of values that are missing a very small amount of data. 

![](https://i.imgur.com/anzrps0.png)


To address the features that have mostly missing data (more than 60% missing; 7 columns), a new boolean column was created indicating whether there was a Null value or not, then the original column was dropped. It did not seem representative of the population to impute a value where a majority of the data was missing, so the route taken.

To address the features where there were a relatively small amount of missing data (less than 1% missing; 24 columns) the null rows were removed. Given there were approximately 8 million data points, removing these miniscule values shouldn't shift the statistics of a given feature by much.

As for the features that were between 1%-60% of missing data, a mode was imputed into the missing data. Looking through the columns a mode was a more relevant imputation strategy compared to the median due to the nature of a lot of the numerics being discrete features rather than continuous.

In addition to null handling, dealing with features with a high correlation was done. After analyzing the Pearson correlation of all features, 4/82 columns had correlation higher than 90% and were dropped. 

```
def shrink_memory_usage(df):
  init_mem_usage = sum(df.memory_usage(deep=True))/1e9

  convert_bool_cols(df)
  shrink_numerics(df)
  object_to_category(df)

  final_mem_usage = sum(df.memory_usage(deep=True))/1e9
  print(f'Memory usage decreased by {init_mem_usage/final_mem_usage}')
```
The function above called three methods to shrink the size of the data. This was a pivotal step because reading the initial dataset took approvximately 5 minutes to read and consumed roughly 15GB of RAM. Pandas by default will assign numbers to a higher bit-value (64/32) depending on if it is an integer or float, and strings take up a lot of memory. To deal with numbers casted too high:
- Any values that only had two uniques were downcasted to a boolean
- Numerics that can be casted down to 32/16/8 bits are downcasted
- Strings are converted to a category datatype which takes up less space

Applything the following shrink function reduced the size of the DataFrame by 7.5 times the initial length. 

Another key discovery was saving the data as a pickle file rather than a CSV. The key advantage to pickling a DataFrame is the pickle file stores the data in such a way that all the downcasted types are remembered and the data is compressed to take up significantly less space. When reading a CSV a dictionary of all datatypes needs to be passed in as a parameter since Pandas will infer data-types if the dictionary isn't passed. Since there are 83 features, its very clear that Pickling has its advantage over reading such a large data file; reading the same dataset as a pickle file took seconds to load compared to 3/5 minutes using the CSV route. 


# Methods - Tyron
## Standardization
To ensure optimal model performance, all numerical features in the data were scaled using sklearn's StandardScaler. Since there is high dimensionality in the data and all the numerical features represent different aspects of hardware and other 
## Encoding Categoricals

## PCA - Dimension Reduction
Since the data provided has high dimensionality one approach taken was to utilize PCA for dimension reduction. Initially, all features were passed into the PCA and the results indicated an issue; over 99% of the explained variance was within the first Principal component. T

![](https://i.imgur.com/31ApcGX.png)

Through experimentation and research, the reason an issue like this happened with this data is due to the fact that categoricals that are encoded shouldn't be utilized in Princical Component Analysis.Encoded features are discete and PCA exploits continuous data into another coordinate system [5]. After filtering PCA to observe just the numeric data a much more interperetable Explained Variance plot is shown below. Based on the interpretation of the graph, if a threshold of 90% variance would be a good point to keep features, that would imply the dimensionality would be reduced by less than 5 features. Since the new dimensionality of this problem is 300 features, it doesn't seem justifiable to remove such a small ratio of the feature space.

![](https://i.imgur.com/QSFLBi0.png)



# Evaluation - Tyron
![](https://i.imgur.com/XUAqyks.png)

# Conclusion - Paul

# Attribution - GitHub stuff (see rubric link)

# Bibliography 
[1] B. Sneel, Mobile threat report, Intel Security, 2016.

[2] G. AV-TEST, AV-TEST The Independent IT-Security Institute, 2017. https://www.av-test.org/en/statistics/malware/ 

[3] I. You, K.Yim, Malware Obfuscation Techniques: A Brief Survey, IEEE, 2010, pp. 297-300.

[4] M. Schiffman, A brief history of malware obfuscation: Part 1 of 2, blogs@cisco - Cisco Blogs, 2010. http://blogs.cisco.com/security/a_brief_history_of_malware_obfuscation_part1_of_2/ 

[5]B. Walker, “PCA is not feature selection,” Medium, 31-Dec-2019. [Online]. Available: https://towardsdatascience.com/pca-is-not-feature-selection-3344fb764ae6. 

# Appendix 















