# Microsoft Malware Prediction
## Satesh Ramnath, Tyron Samaroo, Paul Merisier

# Abstract 
Windows Defender collects telemetry and several key component data on Microsoft machines. An indication of devices that have been subject to Malware are indicated and in this problem; the goal is to predict the probability a Windows Machine has malware. This can be insightful and useful to end-users that would like to know if their machine could potentially be subject to a malware infection given comparable components from previous machines.

Through sampling a portion of this data, several models were found to produce results at a comparable AUC score to the original Kaggle competition. From a classification perspective and the nature of this problem, reducing False Negatives would be better; predicting a Windows machine does not have malware when in truth it does. The Naive Bayes model performed exceptionally well in terms of recall and is believed to be the best model for this problem.

# Introduction 
Given metrics and telemetry data from Windows Defender, the goal of this project is to provide an estimation for how likely a Microsoft computer is to be infected by malware. The significance of this project is to utilize Machine Learning as a tool to explore potential underlying relationships through data Windows Defender collects. In practice this would be a useful tool to enable Microsoft computer owners to understand how likely it is that their computer is at risk for a malware attack.

Mobile devices are subject to 7000+ malware attacks every hour [1]. Additionally, AV-Test (an independent research institute for IT Security from Germany) registers approximately 400,000 new malware per day [2].
Malware authors may dynamically generates malware using obfuscation and replication techniques [3, 4]. Through discovering these facts utilizing machine learning to figure out if a machine is subject to malware would save Windows users from the malware threats that exist. Transparency about security vulnerabilities is one of the problems that companies in the 21st century struggle with, tackling this project will help provide the transparency that is missing. 

To begin, the first strategy is composed of Exploratory Data Analysis to understand the features being dealt with. Next, dealing with the fact that the data is quite large is tackled to allow the data to be digestable for reasonable model training. A comparison of model runtimes are assessed to select a reasonable model to provide a result within a reasonable time. Finally, the selected models undergo hyperparameter tuning and an assessment of which model would give the best results for an end user. The two metrics ultimately used to assess model performance was the leaderboard ROC scores from the original [Kaggle competition](https://www.kaggle.com/competitions/microsoft-malware-prediction/leaderboard) and the recall score of each model.


# Background 
Bad actors with appetite to cause harms, intentionally write malicious software (malware) to infect computing devices. Once a device is infected, the malware may stay latent until a certain period. If the malware remains undetected, a bad actor may decide to exploit the device itself or the information of a victim that may have been saved on the device for tentative gains. Microsoft reports that over one billion enterprise and consumer customers may be at risk of being infected with malicious software. Therefore, it is highly desired to develop robust and efficient malware detection techniques that may even help in preventing the infection of computing devices. 

Malware detections have traditionally been done, by scanning computing devices (programs and applications) and their files for potential malicious software.  The customary host-based techniques are - signature-based detection, checksumming, and whitelisting. In signature-based detection, the antivirus products compare malware unique signature from real-time scans to existing local/remote in-memory patterns. Checksumming enables the verification of malware unique signatures, by calculating the Cyclic Redundancy Check (CRC) to detect if there was the occurrence of an error in the transmission of the data. Finally, in whitelisting the administrator of the computing device has clearly defined a list of allowed applications. Applications that are not whitelisted are then blocked.

Currently, malware authors release mutation engines that are used to create new malware from previously released ones that may be hard to be detected by Antivirus [6]. Due to the dynamic generation of malware, customary Antiviruses struggle to detect day-one malicious software. Therefore, machine learning can help in improving the performance of malware detection programs to increase the security profile of Windows machine.

[7] uses machine learning to detect malware using an energy efficient method. A client-server architecture was presented. The server, hosted on Amazon’s cloud platform, includes a repository of clean and malicious malware on which a detection engine gets continuously trained. Many instances of the detection engine can be spawn at a time to scale the service in high demand, but each instance has its own queue. When a client sends a request to the server to investigate whether a file is clean or malicious, the request is automatically queued. The detection engine pulls the request from the corresponding queue and performs the evaluation. Once the detection engine completes the job, it sends a response back to the client. 

In this project, telemetry data characterizing different windows machines instead of features extracted from files scanned.

# Data
## Microsoft Malware Prediction Kaggle Competition
The original dataset can be observed from the following [Kaggle Competition](https://www.kaggle.com/competitions/microsoft-malware-prediction/data?select=train.csv). 

Since the problem was taken from a Kaggle competition one caveat worth mentioning is there is a train.csv and test.csv. In Kaggle competitions, users only recieve the ground truth to the test.csv results when submitting results to the competition. Since the training data alone had approximately 8 million data points, this project used 33% of train.csv as a holdout set and the rest of the data for training. 

## Data Exploration 
Given the nature of the problem being classification, one of the first things to observe is if the data has balanced or imbalanced classes. From the image below we've identified the probelm is balanced. 

![](https://i.imgur.com/Zo0Sz1h.png)


The data is compromised of approximately 8 million rows and 82 columns. Each row uniquely identifies an individual Windows device, 82 columns represent several features and one column indicates whether the Machine has malware. 

![](https://i.imgur.com/teIzsKv.png)

Above is a distribution of the data-types of each feature;where there is an even balance of numeric-types, categoricals and booleans. 


Examples of numerical features include:
- Total RAM
- Display size 
- CUP core counts 

Examples of boolean features incldue:
- If antivirus is enabled
- If Firewall is enabled
- If the device is a Virtual Machine
- If a machine is gaming based on hardware

Examples of categorical features include:
- Windows Product Type (Windows 7,10 ,etc)
- Engine/OS/Software versions 
- Processor Type

## Data Cleaning

The first step in data cleaning consisted of handling null cases in the dataset. The figure below shows a distribution of the 44 features that contained null values. From a first glance two extremes are quite clear in the Null cases. First, there are 7 features where the total amount of nulls is more than half the entire dataset. Second, there are a lot of values that are missing a very small amount of data. 

![](https://i.imgur.com/anzrps0.png)


To address the features that have mostly missing data (more than 60% missing; 7 columns), a new boolean column was created indicating whether there was a Null value or not, then the original column was dropped. It did not seem representative of the population to impute a value where a majority of the data was missing, so the route taken.

To address the features where there were a relatively small amount of missing data (less than 1% missing; 24 columns) the null rows were removed. Given there were approximately 8 million data points, removing these miniscule values shouldn't shift the statistics of a given feature by much.

As for the features that were between 1%-60% of missing data, a mode was imputed into the missing data. Looking through the columns a mode was a more relevant imputation strategy compared to the median due to the nature of a lot of the numerics being discrete features rather than continuous.

In addition to null handling, dealing with features with a high correlation was done. After analyzing the Pearson correlation of all features, 4/82 columns had correlation higher than 90% and were dropped. 

```python
def shrink_memory_usage(df):
  init_mem_usage = sum(df.memory_usage(deep=True))/1e9

  convert_bool_cols(df)
  shrink_numerics(df)
  object_to_category(df)

  final_mem_usage = sum(df.memory_usage(deep=True))/1e9
  print(f'Memory usage decreased by {init_mem_usage/final_mem_usage}')
```
The function above called three methods to shrink the size of the data. This was a pivotal step because reading the initial dataset took approvximately 5 minutes to read and consumed roughly 15GB of RAM. Pandas by default will assign numbers to a higher bit-value (64/32) depending on if it is an integer or float, and strings take up a lot of memory. To deal with numbers casted too high:
- Any values that only had two uniques were downcasted to a boolean
- Numerics that can be casted down to 32/16/8 bits are downcasted
- Strings are converted to a category datatype which takes up less space

Applything the following shrink function reduced the size of the DataFrame by 7.5 times the initial length. 

Another key discovery was saving the data as a pickle file rather than a CSV. The key advantage to pickling a DataFrame is the pickle file stores the data in such a way that all the downcasted types are remembered and the data is compressed to take up significantly less space. When reading a CSV a dictionary of all datatypes needs to be passed in as a parameter since Pandas will infer data-types if the dictionary isn't passed. Since there are 83 features, its very clear that Pickling has its advantage over reading such a large data file; reading the same dataset as a pickle file took seconds to load compared to 3/5 minutes using the CSV route. 


# Methods
## Standardization
To ensure optimal model performance, all numerical features in the data were scaled using sklearn's StandardScaler. Since there is high dimensionality in the data and all the numerical features represent different aspects of hardware and other 
## Encoding Categoricals
The dataset consisted of a mixture of both nominal and and ordinal categorical values; 4 ordinals and 22 categoricals.

The ordinal categories went through an ordinal encoder, where the training set underwent training and the test set was fitted on encoded labels. To deal with the case where unseen test categories, a predefined unknown value of -1 was passed into those categories.

A majority of the cateogicals were nominal and the distribution of the unique values can be observed below.
![](https://i.imgur.com/jHBNPtA.png)

The OsBuildLab categeory is overwhelmingly large, and if it were One Hot Encoded this one feature alone would increase the feature space by 7 times its original dimensionality. Looking into this feature, the processor of a machine was extracted from it and the unique cateogories for processors were 3, significantly less. Below depicts the new distribution of categoricals to be One Hot Encoded. 
![](https://i.imgur.com/59gP777.png)

With a more balanced distribution of nominal categoricals, the trained dataset was fitted and the test values were transformed. To deal with unseen nominal values, all zeros are passed through each One Hot Encoded column to indicate an unseen category. 

## PCA - Dimension Reduction
Since the data provided has high dimensionality one approach taken was to utilize PCA for dimension reduction. Initially, all features were passed into the PCA and the results indicated an issue; over 99% of the explained variance was within the first Principal component. 

![](https://i.imgur.com/31ApcGX.png)

Through experimentation and research, the reason an issue like this happened with this data is due to the fact that categoricals that are encoded shouldn't be utilized in Princical Component Analysis.Encoded features are discete and PCA exploits continuous data into another coordinate system [5]. After filtering PCA to observe just the numeric data a much more interperetable Explained Variance plot is shown below. Based on the interpretation of the graph, if a threshold of 90% variance would be a good point to keep features, that would imply the dimensionality would be reduced by less than 5 features. Since the new dimensionality of this problem is 300 features, it doesn't seem justifiable to remove such a small ratio of the feature space.

![](https://i.imgur.com/QSFLBi0.png)

## Models Selection
To solve this classification problem it was decided to take an aggegate of classification model. Majority from Scikit-Learn and one known open source SoTA model XGBboost. 

### Models
- Logistic Regression
- K-Nearest Neighbors
- Support Vector Machine
- Random Forest 
- Naive Bayes 
- XGBoost

Given the massive size of the data the model pipeline suffered from runtime issues. Instead a sample of the data and remove models that exponentially increase in time. 
![](https://i.imgur.com/XUAqyks.png)

After evaluating the model runtime three models were selected to continue experimentation.
### Remaining Models 
- Random Forest 
- Naive Bayes 
- XGBoost 

### Model Validation 
After reducing the amount of models to evaluate on the entire data on, the next step would be training. To verify that the model will do well on on seen data a stratified five fold cross validation. AUROC metric is used to measure how well the model did. AUROC is a known metric that is used for classification problems, it tells us how much the model is capable of distinguishing the classes.Additionally, the AUROC score was utilized in the Kaggle competition this data originates from, so it will be used as a baseline metric.

From the results it can be noted that the algorithm and the data is consistent.This means when testing on seen data there is confidence that the model will do well. The large amount of data is the main reason why there is not much variance with the cross validation. Random Forest, Naive Bayes and XGBoost all preformed similarly. 
### Naive Bayes AUROC
![](https://i.imgur.com/eWq3rT2.png)




# Evaluation



After choosing the best models and validate all discrepancy work was done on hyperparamter tuning. An aggregate of parameters was chosen for each model and was then ran through a random search. Using the most optimial parameters the model was then trained on all of the training data. After a one time prediction was done on the test set that has been unseen. Again AUROC was looked at as a metric and the Precision vs Recall Curve.


## Results
The Naive Bayes model return a result score of AUROC of 0.63. It might not look like much but when compared to the to the top AUROC score on [Kaggle](https://www.kaggle.com/competitions/microsoft-malware-prediction/leaderboard?) 0.65 its only different by 0.02%! In the figure below it can be see that the test set preformed  almost identical to the training and testing on validation data. One big difference between the model is is that recall did better, this can be acredited to a beter tuned model.
![](https://i.imgur.com/7CjTRXJ.png)

## Feature Importance

Since Naive Bayes is a probalistic model it is not possible to look at feature imporatance. Instead, Random Forest and XGBoost were looked at closely to understand feature importance. Looking at all 299 features, 10 of them stood out the most for both tree-based models shown in the image below. 

Of the ten features that contributed most to the Random Forest, there appears to be a bias towards features that have a high cardinality; which is common behavior for tree-based models. A lot of the features were One Hot Encoded, thereby giving a cardinality of 2; the data began with an even balance of numerics, booleans, and categoricals. However, once gone through the encoding process, the percentage of binary encoded values increased the feature-space by 2.5 its original size. Since XGBoost is also a tree-based ensemble, the expectation for feature importance pattern should remain the same. 

### Random Forest
The most important feature **SmartScreen_ExistsNotSet** is known by Microsoft as the Microsoft Defender SmartScreen filter in Windows 10. It help mitigate risk against phishing and malicious software on visited website and applications in use. Micorosoft even recommends to keep it always enabled [8]. 

![](https://i.imgur.com/pZRCtBk.png)

### XGBoost
As for XGBoost the feature importances follow a similar pattern in comparison to Random Forest. Hence, the logic about tree-based models having bias towards high cardinality features holds true. Of the 10 featurues selected, a noteworthy set of features that allowed XGBoost to perform well were Anti-virus software related features; AVSigVersion, AVProductStatesIdentifier, and AVProducts installed.

![](https://i.imgur.com/5u65tj3.png)


## Model Metrics 
While the AUROC shows how well the model did and how it preformed to others a closer look at recall can give valuable insight. Recall is important because a reduce in false negatives is needed. Reducing false negatives means that a malware is reported as not being a malware when in fact it is a malware. Given that recall hold such importance Naive Bayes is chosen as the final model since it did well on recall and fits the specific needs of the project goal. 

The reason why Naive Bayes did so well and return such a high recall is because it is a probablistic model that generalizes well. Models like Random Forest and XGBoost are more advanced models that overfit on the data but focus on getting good accurarcy but sacrifices recall. 
![](https://i.imgur.com/D49GzNT.png)
![](https://i.imgur.com/NXHzN6w.png)



# Conclusion
Machine learning techniques can be used to adapt with the dynamic nature of malware generation to help enhance current security mechanisms effectiveness in detecting malicious software. Our objective is two-fold, obtaining high recall to mitigate customer impact and reducing false negatives. Finally recall is the final metric used in determining the success of the models. Recall calculated how many true positives were found meaning that it tries to mitigate reporting positives as false. Having high recall allows to mitigate customer impact. 

The model that did this the best end up being Naive Bayes which was the final model choosen; which had an ROC score of 0.63. Compared to the original Kaggle competition, the best scores were roughly around 0.66. If ROC score alone was the factor to decide which model performed best, Random Forest in this project would be the winner; it had an ROC score of 0.69. One caveat is, the test set used in this project subsetted the training set alone since results of the test set are not disclosed unless you're competing in the Kaggle competition. Since recall is also another deciding factor to reduce False Negatives, Naive Bayes outperformed XGBoost and Random forest hence making it the best believed model for this problem.


# Attribution 
![](https://i.imgur.com/Rkesh6b.png)
![](https://i.imgur.com/J6WqQMC.png)
Tyron Samaroo
- Model Exploration 
- Model Building 
- Model Programatic Design
Satesh Ramnath
- EDA
- Data Cleaning
- Model Assessment

Paul Merisier
- EDA
- Hyperparameter Tuning
- Background Research


# Bibliography 
[1] B. Sneel, Mobile threat report, Intel Security, 2016.

[2] G. AV-TEST, AV-TEST The Independent IT-Security Institute, 2017. https://www.av-test.org/en/statistics/malware/ 

[3] I. You, K.Yim, Malware Obfuscation Techniques: A Brief Survey, IEEE, 2010, pp. 297-300.

[4] M. Schiffman, A brief history of malware obfuscation: Part 1 of 2, blogs@cisco - Cisco Blogs, 2010. http://blogs.cisco.com/security/a_brief_history_of_malware_obfuscation_part1_of_2/ 

[5]B. Walker, “PCA is not feature selection,” Medium, 31-Dec-2019. [Online]. Available: https://towardsdatascience.com/pca-is-not-feature-selection-3344fb764ae6. 

[6] Bruschi, D., Martignoni, L., Monga, M. (2006). Detecting Self-mutating Malware Using Control-Flow Graph Matching. In: Büschkes, R., Laskov, P. (eds) Detection of Intrusions and Malware & Vulnerability Assessment. DIMVA 2006. Lecture Notes in Computer Science, vol 4064. Springer, Berlin, Heidelberg. https://doi.org/10.1007/11790754_8

[7] Qublai K. Ali Mirza, Irfan Awan, Muhammad Younas (2018). CloudIntell: An intelligent malware detection system. Future Generation Computer Systems, Volume 86, 2018, Pages 1042-1053

[8] Mjcaparas, “Microsoft Defender SmartScreen Overview (windows) - windows security,” overview (Windows) - Windows security | Microsoft Docs. [Online]. Available: https://docs.microsoft.com/en-us/windows/security/threat-protection/microsoft-defender-smartscreen/microsoft-defender-smartscreen-overview. [Accessed: 25-May-2022]. 














